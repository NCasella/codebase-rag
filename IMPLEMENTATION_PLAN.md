# Plan de ImplementaciÃ³n: Config System + Interactive Chat

Este documento detalla los pasos para implementar dos nuevas features:
1. **Sistema de configuraciÃ³n con archivos JSON**
2. **Chat interactivo con contexto conversacional**

---

## FASE 1: Sistema de ConfiguraciÃ³n JSON

### Objetivo
Permitir configurar todos los parÃ¡metros del sistema (modelo, retrieval, text splitting, embeddings) mediante archivos JSON, facilitando experimentaciÃ³n y reproducibilidad.

### Pasos de implementaciÃ³n

#### 1.1 Crear estructura de carpetas
```bash
mkdir configs
```

**Archivos a crear:**
- `configs/default.json` - ConfiguraciÃ³n balanceada
- `configs/optimal.json` - Mejor calidad (usa prompt optimal)
- `configs/fast.json` - Respuestas rÃ¡pidas
- `configs/detailed.json` - AnÃ¡lisis profundo

#### 1.2 DiseÃ±ar schema JSON
**Archivo**: `configs/default.json`

```json
{
  "name": "default",
  "description": "ConfiguraciÃ³n balanceada para uso general",
  "prompt_template": "default",
  "model": {
    "name": "gpt-4.1-nano",
    "temperature": 0.1
  },
  "retrieval": {
    "k_documents": 5,
    "similarity_threshold": null
  },
  "text_splitting": {
    "chunk_size": 1000,
    "chunk_overlap": 200
  },
  "embeddings": {
    "model_name": "sentence-transformers/all-MiniLM-L6-v2"
  }
}
```

#### 1.3 Crear config loader
**Archivo nuevo**: `src/config_loader.py`

**Funcionalidades:**
- Clase `RAGConfig` con dataclass o pydantic
- MÃ©todo `load_from_json(path)`
- MÃ©todo `validate()` para validar parÃ¡metros
- Valores por defecto si falta algÃºn campo
- Manejo de errores (archivo no existe, JSON invÃ¡lido)

**Dependencias:**
```python
from dataclasses import dataclass
from pathlib import Path
import json
```

#### 1.4 Modificar ChromaCollection
**Archivo**: `src/inserter.py`

**Cambios necesarios:**
- Modificar `__init__()` para aceptar parÃ¡metro opcional `config: RAGConfig`
- Si se pasa `config`, usar sus valores en lugar de hardcoded
- Mantener retrocompatibilidad (parÃ¡metros individuales siguen funcionando)

**Ejemplo:**
```python
def __init__(
    self,
    collection_name: str,
    prompt_template: str = "default",
    config: RAGConfig | None = None
):
    if config:
        prompt_template = config.prompt_template
        self.model_config = config.model
        self.retrieval_config = config.retrieval
    # ...
```

#### 1.5 Modificar text_splitter
**Archivo**: `src/text_splitter.py`

**Cambios:**
- Modificar funciones para aceptar parÃ¡metros de chunk_size y chunk_overlap
- Actualmente estÃ¡n hardcodeados
- Pasar estos valores desde main.py usando la config

#### 1.6 Integrar en CLI
**Archivo**: `main.py`

**Cambios:**
- Agregar argumento `--config` al parser
- Cargar config si se especifica
- Pasar config a ChromaCollection
- Mostrar config activa en los logs de fase

**Ejemplo CLI:**
```bash
python main.py -z code.zip -p "pregunta" --config configs/optimal.json
```

#### 1.7 Testing
- Crear configs de prueba
- Verificar que cada config funciona
- Verificar retrocompatibilidad (sin --config sigue funcionando)

#### 1.8 DocumentaciÃ³n
- Actualizar README.md con secciÃ³n de configuraciÃ³n
- Documentar schema JSON
- Agregar ejemplos de configs

---

## FASE 2: Chat Interactivo con Contexto

### Objetivo
Crear interfaz REPL que permita conversaciÃ³n continua con el asistente, manteniendo contexto entre preguntas sin re-indexar.

### Pasos de implementaciÃ³n

#### 2.1 Crear ChatSession manager
**Archivo nuevo**: `src/chat_session.py`

**Funcionalidades:**
```python
class ChatSession:
    def __init__(self, chroma: ChromaCollection, config: RAGConfig):
        self.chroma = chroma
        self.config = config
        self.history = []  # Lista de {"role": "user/assistant", "content": "..."}
        self.max_history = 10  # Sliding window

    def add_user_message(self, content: str) -> None:
        """Agregar mensaje del usuario al historial"""

    def add_assistant_message(self, content: str) -> None:
        """Agregar respuesta del asistente al historial"""

    def get_history_context(self) -> list[dict]:
        """Retornar Ãºltimos N mensajes para contexto"""

    def clear_history(self) -> None:
        """Limpiar historial de conversaciÃ³n"""

    def ask(self, query: str, verbose: bool = False) -> str:
        """
        Hacer pregunta con contexto de historial.
        1. Agregar query al historial
        2. Hacer retrieval de documentos relevantes
        3. Construir mensajes con historial + documentos
        4. Llamar a OpenAI
        5. Agregar respuesta al historial
        6. Retornar respuesta
        """
```

#### 2.2 Modificar ChromaCollection para contexto
**Archivo**: `src/inserter.py`

**OpciÃ³n A (simple)**:
- Crear mÃ©todo `rag_with_history(query, history, verbose)`
- Similar a `rag()` pero acepta lista de mensajes previos
- Retrieval usa solo query actual
- Generation usa historial completo

**OpciÃ³n B (avanzado)**:
- Implementar query reformulation usando historial
- Antes de retrieval, reformular query considerando contexto
- MÃ¡s preciso pero mÃ¡s complejo y costoso

**RecomendaciÃ³n**: Empezar con OpciÃ³n A

#### 2.3 Crear interfaz REPL
**Archivo**: `main.py` (agregar modo chat)

**Funcionalidades:**
- Detectar flag `--chat` en CLI
- Si estÃ¡ activo, entrar en loop interactivo despuÃ©s de indexar
- Input loop con `input()` o librerÃ­a `prompt_toolkit` (mÃ¡s avanzado)
- Comandos especiales:
  - `exit` o `quit` - Salir
  - `/clear` - Limpiar historial
  - `/history` - Mostrar historial
  - `/config` - Mostrar configuraciÃ³n activa
  - `/help` - Ayuda de comandos

**Pseudo-cÃ³digo:**
```python
if args.chat:
    session = ChatSession(chroma, config)
    print("Modo chat activado. Escribe 'exit' para salir.\n")

    while True:
        try:
            user_input = input("> ").strip()

            if user_input in ["exit", "quit"]:
                break

            if user_input.startswith("/"):
                handle_command(user_input, session)
                continue

            if not user_input:
                continue

            response = session.ask(user_input, verbose=args.verbose)
            print(f"\n{response}\n")

        except KeyboardInterrupt:
            print("\n\nSaliendo...")
            break
        except Exception as e:
            print(f"Error: {e}")
```

#### 2.4 Mejorar UX del chat
**Mejoras opcionales:**

**2.4.1 ColorizaciÃ³n de output**
- Usar `rich` o `colorama`
- User input en un color, respuesta en otro
- Comandos especiales resaltados

**2.4.2 Better input handling**
- Usar `prompt_toolkit` para:
  - Historial de comandos (flecha arriba)
  - Auto-completado
  - Multi-lÃ­nea
  - Sintaxis highlighting

**2.4.3 Indicadores visuales**
- Spinner mientras piensa
- Progress bar para retrieval
- Typing indicator

#### 2.5 Implementar sliding window
**Archivo**: `src/chat_session.py`

**Problema**: Historial muy largo = demasiados tokens = costoso y lento

**SoluciÃ³n**:
- Mantener solo Ãºltimos N mensajes (ej: 10)
- Opcionalmente: system message con resumen de conversaciÃ³n antigua
- Configurar N en config JSON

#### 2.6 Manejo de contexto en retrieval
**ConsideraciÃ³n importante:**

Cuando el usuario pregunta:
```
User: "Â¿QuÃ© hace la funciÃ³n login?"
Assistant: "La funciÃ³n login valida credenciales..."
User: "Â¿Y quÃ© pasa si falla?"  â† "falla" se refiere a login
```

**Opciones:**

**A) Retrieval solo de query actual (mÃ¡s simple)**
- Busca documentos relevantes a "Â¿Y quÃ© pasa si falla?"
- Puede no encontrar documentos relevantes
- Pero el historial en generation ayuda

**B) Query reformulation (mÃ¡s preciso)**
```python
def reformulate_query(query: str, history: list) -> str:
    # Usar LLM para reformular query considerando historial
    # Input: "Â¿Y quÃ© pasa si falla?" + historial
    # Output: "Â¿QuÃ© pasa si la funciÃ³n login falla?"
    return reformulated_query
```
- MÃ¡s costoso (llamada extra a LLM)
- Mejor retrieval
- Implementar en Fase 2B (despuÃ©s)

#### 2.7 Testing del chat
- Probar conversaciones de varios turnos
- Verificar que el contexto se mantiene
- Probar comandos especiales
- Verificar que sliding window funciona
- Testear con diferentes configs

#### 2.8 DocumentaciÃ³n
- Actualizar README con modo chat
- Documentar comandos especiales
- Agregar ejemplos de conversaciones
- Explicar lÃ­mites de contexto

---

## Orden de ImplementaciÃ³n Recomendado

### Sprint 1: Config System (estimado: 2-3 horas)
```
1. Crear configs/ con JSONs
2. Implementar src/config_loader.py
3. Modificar src/inserter.py para usar configs
4. Modificar src/text_splitter.py para usar configs
5. Integrar en main.py
6. Testing bÃ¡sico
7. Actualizar README
```

### Sprint 2: Chat BÃ¡sico (estimado: 3-4 horas)
```
1. Implementar src/chat_session.py (sin sliding window aÃºn)
2. Agregar mÃ©todo rag_with_history() a ChromaCollection
3. Crear loop REPL bÃ¡sico en main.py
4. Implementar comandos /exit, /clear, /history
5. Testing de conversaciones multi-turn
```

### Sprint 3: Chat Avanzado (estimado: 2-3 horas)
```
1. Implementar sliding window en ChatSession
2. Agregar colorizaciÃ³n con rich/colorama
3. Mejorar UX con indicadores visuales
4. Agregar mÃ¡s comandos Ãºtiles (/config, /help, /docs)
5. Testing exhaustivo
6. DocumentaciÃ³n completa
```

### Sprint 4 (Opcional): Query Reformulation
```
1. Implementar reformulate_query() en ChatSession
2. Comparar resultados con/sin reformulation
3. Hacer configurable en JSON
4. Documentar trade-offs
```

---

## Dependencias Nuevas

Agregar a `requirements.txt`:
```
rich>=13.0.0          # Para colorizaciÃ³n y mejor UX
prompt_toolkit>=3.0   # Para mejor input handling (opcional)
```

---

## Decisiones de DiseÃ±o

### Â¿Por quÃ© JSON para configs?
- âœ… Legible y editable manualmente
- âœ… EstÃ¡ndar ampliamente usado
- âœ… FÃ¡cil de versionar en git
- âŒ Alternativas: YAML (mÃ¡s complejo), TOML (menos comÃºn en ML)

### Â¿Por quÃ© no usar LangChain ConversationChain?
- âœ… Control total sobre el historial
- âœ… MÃ¡s simple y transparente
- âœ… Menos dependencias
- âŒ Pero se podrÃ­a migrar despuÃ©s si se necesita

### Â¿Sliding window vs. Summarization?
- **Sliding window**: Mantener Ãºltimos N mensajes
  - âœ… Simple, rÃ¡pido, predecible
  - âŒ Pierde contexto antiguo completamente
- **Summarization**: Resumir historial antiguo
  - âœ… Mantiene contexto antiguo
  - âŒ Costoso, complejo, puede perder detalles
- **DecisiÃ³n**: Empezar con sliding window, evaluar summarization despuÃ©s

---

## Checklist de ImplementaciÃ³n

### Fase 1: Config System
- [ ] Crear carpeta `configs/`
- [ ] Crear `configs/default.json`
- [ ] Crear `configs/optimal.json`
- [ ] Crear `configs/fast.json`
- [ ] Crear `configs/detailed.json`
- [ ] Implementar `src/config_loader.py`
- [ ] Modificar `ChromaCollection.__init__()` para usar config
- [ ] Modificar `text_splitter.py` para usar config
- [ ] Agregar flag `--config` al CLI
- [ ] Testing de configs
- [ ] Actualizar README

### Fase 2: Chat Interactivo
- [ ] Implementar `src/chat_session.py`
- [ ] Agregar `rag_with_history()` a `ChromaCollection`
- [ ] Crear loop REPL en `main.py`
- [ ] Implementar comando `/exit`
- [ ] Implementar comando `/clear`
- [ ] Implementar comando `/history`
- [ ] Implementar comando `/config`
- [ ] Implementar comando `/help`
- [ ] Implementar sliding window
- [ ] Agregar colorizaciÃ³n con `rich`
- [ ] Testing de conversaciones
- [ ] Actualizar README con modo chat

### Fase 3 (Opcional): Mejoras avanzadas
- [ ] Implementar query reformulation
- [ ] Agregar `prompt_toolkit` para mejor input
- [ ] Agregar spinners y progress bars
- [ ] Implementar logging de sesiones
- [ ] Agregar export de conversaciones

---

## Preguntas para decidir

Antes de empezar, definir:

1. **Â¿QuÃ© parÃ¡metros incluir en config?**
   - Â¿Solo los mencionados o mÃ¡s?
   - Â¿Incluir parÃ¡metros de ChromaDB (distance function, etc)?

2. **Â¿Sliding window size?**
   - Â¿10 mensajes? Â¿20? Â¿Configurable?

3. **Â¿LibrerÃ­as de UX?**
   - Â¿Usar `rich` para colorizaciÃ³n?
   - Â¿Usar `prompt_toolkit` para input mejorado?
   - Â¿O mantenerlo simple con input() bÃ¡sico?

4. **Â¿Query reformulation?**
   - Â¿Implementarlo desde el inicio o dejarlo para despuÃ©s?

5. **Â¿Verbose en chat?**
   - Â¿Mostrar documentos recuperados en cada query?
   - Â¿Hacer que sea toggleable con `/verbose`?

---

## Resultado Final Esperado

### CLI con config:
```bash
python main.py -z code.zip --config configs/optimal.json -p "Â¿QuÃ© hace main.py?"
# Usa configuraciÃ³n optimal (mejor calidad)
```

### CLI con chat interactivo:
```bash
python main.py -z code.zip --config configs/fast.json --chat

============================================================
  CODEBASE RAG - MODO CHAT INTERACTIVO
============================================================

ðŸ“¦ Indexando: code.zip
ðŸ“Š ColecciÃ³n: codeRAG
ðŸŽ¯ Config: configs/fast.json (gpt-3.5-turbo, k=3)

âœ… Listo! 250 fragmentos indexados

Comandos: /help /clear /history /config /exit

> Â¿QuÃ© hace la funciÃ³n login?

La funciÃ³n login en auth.py:42 valida las credenciales del usuario
contra la base de datos y retorna un JWT si son vÃ¡lidas...

> Â¿Y quÃ© pasa si las credenciales son incorrectas?

Si las credenciales son incorrectas, la funciÃ³n retorna un status 401
con el mensaje "Invalid credentials"...

> /history

Historial (2 mensajes):
1. User: Â¿QuÃ© hace la funciÃ³n login?
2. Assistant: La funciÃ³n login en auth.py:42...
3. User: Â¿Y quÃ© pasa si las credenciales son incorrectas?
4. Assistant: Si las credenciales son incorrectas...

> exit

Â¡Hasta luego!
```

---

## EstimaciÃ³n Total

- **Fase 1 (Config System)**: 2-3 horas
- **Fase 2 (Chat BÃ¡sico)**: 3-4 horas
- **Fase 3 (Chat Avanzado)**: 2-3 horas
- **Total**: 7-10 horas

**RecomendaciÃ³n**: Implementar en orden, validar cada fase antes de continuar.
