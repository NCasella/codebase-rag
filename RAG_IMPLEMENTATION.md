# ImplementaciÃ³n RAG - GuÃ­a TÃ©cnica Completa

Este documento explica el pipeline RAG implementado, cÃ³mo funciona cada componente y el estado actual del proyecto.

---

## ðŸ“‹ Ãndice

1. [Arquitectura General del RAG](#arquitectura-general-del-rag)
2. [Pipeline de IndexaciÃ³n (Indexing Pipeline)](#pipeline-de-indexaciÃ³n)
3. [IntegraciÃ³n con ChromaDB](#integraciÃ³n-con-chromadb)
4. [Text Splitting](#text-splitting)
5. [IntegraciÃ³n con OpenAI](#integraciÃ³n-con-openai)
6. [Pipeline de Consulta (Query Pipeline)](#pipeline-de-consulta)
7. [Estado de ImplementaciÃ³n](#estado-de-implementaciÃ³n)
8. [CÃ³mo Ejecutar el Sistema](#cÃ³mo-ejecutar-el-sistema)

---

## Arquitectura General del RAG

### Â¿QuÃ© es RAG?

**RAG (Retrieval-Augmented Generation)** combina dos tÃ©cnicas:
- **Retrieval**: Buscar informaciÃ³n relevante en una base de datos
- **Generation**: Usar un LLM (GPT) para generar respuestas basadas en esa informaciÃ³n

### Pipeline Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FASE 1: INDEXACIÃ“N                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Archivos ZIP â†’ ExtracciÃ³n â†’ DetecciÃ³n Lenguaje â†’ Parseo â†’
â†’ Text Splitting â†’ GeneraciÃ³n Embeddings â†’ ChromaDB

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FASE 2: CONSULTA                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Pregunta Usuario â†’ Embedding Query â†’ BÃºsqueda Similaridad â†’
â†’ Recuperar Top-K â†’ Construir Prompt â†’ GPT â†’ Respuesta
```

---

## Pipeline de IndexaciÃ³n

### Estado: âœ… IMPLEMENTADO

El indexing pipeline transforma el cÃ³digo fuente en embeddings vectoriales almacenados en ChromaDB.

### Flujo de Datos

#### 1. **Carga de Archivos** (`text_splitter.py`)

```python
# Archivo: src/text_splitter.py
# FunciÃ³n: load_from_zipfile()

ZIP File â†’ ExtracciÃ³n temporal â†’ Listado de archivos
```

**ImplementaciÃ³n actual:**
- âœ… Extrae ZIP a directorio temporal con `tempfile.TemporaryDirectory()`
- âœ… Recorre recursivamente todos los archivos con `os.walk()`
- âœ… Filtra archivos ocultos (`.git`, `.DS_Store`, etc.)
- âœ… Limpia automÃ¡ticamente archivos temporales al terminar

**CÃ³digo clave:**
```python
with tempfile.TemporaryDirectory() as temp_dir:
    with ZipFile(zippath, 'r') as zip_file:
        zip_file.extractall(temp_dir)
        # Procesar archivos...
```

#### 2. **DetecciÃ³n de Lenguaje** (`language_detector.py`)

```python
# Archivo: src/utils/language_detector.py
# Funciones: is_supported(), detect_language()

Archivo â†’ ExtensiÃ³n â†’ LANGUAGE_MAP â†’ Lenguaje
```

**ImplementaciÃ³n actual:**
- âœ… 50+ extensiones soportadas (Python, JS, TS, Java, Go, Rust, etc.)
- âœ… Filtrado automÃ¡tico de archivos no soportados
- âœ… DetecciÃ³n case-insensitive (`.PY` = `.py`)

**CÃ³digo clave:**
```python
if not is_supported(filepath):
    print(f"âŠ˜ Saltando (no soportado): {filename}")
    continue

language = detect_language(filepath)  # "python", "javascript", etc.
```

#### 3. **Parseo de CÃ³digo** (`text_splitter.py`)

```python
# Archivo: src/text_splitter.py
# FunciÃ³n: parse_file()

Archivo â†’ LanguageParser â†’ Fragmentos (Documents)
```

**ImplementaciÃ³n actual:**
- âœ… Usa `LanguageParser` de Langchain (consciente del lenguaje)
- âœ… Parser threshold configurable (default: 3)
- âœ… Respeta la estructura sintÃ¡ctica del cÃ³digo
- âœ… Manejo de errores por archivo (un error no detiene todo)

**CÃ³digo clave:**
```python
parser = LanguageParser(parser_threshold=3)
blob = Blob(path=filepath)
docs = parser.lazy_parse(blob=blob)
```

**Â¿QuÃ© hace el parser?**
- Identifica funciones, clases, mÃ©todos automÃ¡ticamente
- Divide el cÃ³digo en fragmentos significativos
- Preserva contexto sintÃ¡ctico (no corta a mitad de funciÃ³n)

#### 4. **Enriquecimiento de Metadata** (`text_splitter.py`)

```python
Fragmentos â†’ Agregar metadata â†’ Documents enriquecidos
```

**ImplementaciÃ³n actual:**
- âœ… Agrega `source_file` (nombre del archivo)
- âœ… Agrega `language` (lenguaje detectado)
- âœ… Preserva metadata original del parser

**CÃ³digo clave:**
```python
for doc in docs:
    doc.metadata['source_file'] = filename
    doc.metadata['language'] = detect_language(filepath)
```

---

## IntegraciÃ³n con ChromaDB

### Estado: âœ… IMPLEMENTADO

ChromaDB es la base de datos vectorial que almacena los embeddings del cÃ³digo.

### Â¿Por quÃ© ChromaDB?

- ðŸš€ **RÃ¡pido**: Optimizado para bÃºsqueda de similaridad
- ðŸ’¾ **Local**: No requiere servidor externo
- ðŸ”Œ **FÃ¡cil integraciÃ³n**: API simple
- ðŸŽ¯ **Embeddings automÃ¡ticos**: Genera vectores automÃ¡ticamente

### Componentes Implementados

#### 1. **InicializaciÃ³n de ColecciÃ³n** (`inserter.py`)

```python
# Archivo: src/inserter.py
# FunciÃ³n: _initialize_collection()

Nombre â†’ Verificar existencia â†’ Crear/Recuperar â†’ Collection
```

**ImplementaciÃ³n:**
- âœ… Idempotente (puedes llamarlo mÃºltiples veces)
- âœ… Usa funciÃ³n de embedding global (SentenceTransformer/BERT)
- âœ… Cliente global compartido

**CÃ³digo clave:**
```python
_embedding_function = SentenceTransformerEmbeddingFunction()
_chroma_client = chromadb.Client()

def _initialize_collection(collection_name: str):
    if collection_name not in existing_collections:
        return _chroma_client.create_collection(
            name=collection_name,
            embedding_function=_embedding_function
        )
    else:
        return _chroma_client.get_collection(name=collection_name)
```

#### 2. **InserciÃ³n de Documentos** (`inserter.py`)

```python
# Archivo: src/inserter.py
# MÃ©todo: ChromaCollection.insert_docs()

Documents â†’ Extraer contenido â†’ ChromaDB.add() â†’ Embeddings generados
```

**ImplementaciÃ³n:**
- âœ… Genera IDs Ãºnicos con UUID4
- âœ… ChromaDB genera embeddings automÃ¡ticamente
- âœ… Almacena: contenido + metadata + embeddings

**CÃ³digo clave:**
```python
self._chroma_collection.add(
    ids=[str(uuid4()) for _ in docs],
    documents=[doc.page_content for doc in docs],
    metadatas=[doc.metadata for doc in docs]
)
```

**Nota importante:** ChromaDB genera los embeddings automÃ¡ticamente usando la funciÃ³n de embedding configurada (SentenceTransformer). No necesitas calcular vectores manualmente.

#### 3. **BÃºsqueda por Similaridad** (`inserter.py`)

```python
# Archivo: src/inserter.py
# MÃ©todo: ChromaCollection.retrieve_k_similar_docs()

Query â†’ Embedding â†’ BÃºsqueda vectorial â†’ Top-K documentos
```

**ImplementaciÃ³n:**
- âœ… BÃºsqueda semÃ¡ntica (no keyword matching)
- âœ… K configurable (default: 5)
- âœ… Incluye documentos y embeddings en resultados

**CÃ³digo clave:**
```python
results = self._chroma_collection.query(
    query_texts=[query],
    n_results=k,
    include=['documents', 'embeddings']
)
```

### Â¿QuÃ© hay de Pinecone?

**Estado: âŒ NO IMPLEMENTADO (no necesario)**

Pinecone es otra base de datos vectorial, pero para este proyecto:
- âœ… ChromaDB es suficiente (local, gratuito, rÃ¡pido)
- âŒ Pinecone requiere cuenta y es de pago para producciÃ³n
- ðŸ’¡ Puedes migrar a Pinecone despuÃ©s si necesitas:
  - Escalabilidad masiva (millones de documentos)
  - Acceso distribuido/multi-regiÃ³n
  - Alta disponibilidad

**Para tu TP acadÃ©mico: ChromaDB es la elecciÃ³n correcta.**

---

## Text Splitting

### Estado: âœ… IMPLEMENTADO

El text splitting divide archivos grandes en fragmentos manejables.

### Â¿Por quÃ© es importante?

- ðŸŽ¯ **PrecisiÃ³n**: Fragmentos pequeÃ±os = bÃºsquedas mÃ¡s precisas
- ðŸ’° **Costos**: GPT tiene lÃ­mites de tokens y cobra por token
- ðŸ§  **Contexto**: Fragmentos enfocados = mejores respuestas

### Estrategia Implementada

#### 1. **LanguageParser** (Langchain)

```python
parser = LanguageParser(parser_threshold=3)
```

**CaracterÃ­sticas:**
- âœ… Consciente de la sintaxis del lenguaje
- âœ… No corta funciones o clases a la mitad
- âœ… Preserva contexto estructural
- âœ… Threshold configurable (min tamaÃ±o de fragmento)

#### 2. **Parser Threshold**

```python
parser_threshold = 3  # TamaÃ±o mÃ­nimo de fragmento
```

**Valores tÃ­picos:**
- `1-3`: Fragmentos muy pequeÃ±os (alta granularidad)
- `3-5`: Balance recomendado âœ… (implementado)
- `5-10`: Fragmentos mÃ¡s grandes (menos precisiÃ³n pero mÃ¡s contexto)

### Ejemplo de FragmentaciÃ³n

**Archivo original:**
```python
# models.py (100 lÃ­neas)
class Usuario:
    def __init__(self, nombre):
        self.nombre = nombre

    def saludar(self):
        return f"Hola, {self.nombre}"

class Producto:
    def __init__(self, nombre, precio):
        self.nombre = nombre
        self.precio = precio
```

**Fragmentos generados:**
```
Fragment 1: class Usuario + __init__ + saludar (20 lÃ­neas)
Fragment 2: class Producto + __init__ (15 lÃ­neas)
```

### Metadata de Fragmentos

Cada fragmento incluye:
```python
{
    "source_file": "models.py",
    "language": "python",
    "start_line": 10,      # Del parser
    "end_line": 25,        # Del parser
}
```

---

## IntegraciÃ³n con OpenAI

### Estado: âœ… IMPLEMENTADO

OpenAI GPT-4.1-nano genera las respuestas finales usando el contexto recuperado.

### Flujo de IntegraciÃ³n

#### 1. **InicializaciÃ³n del Cliente** (`inserter.py`)

```python
# Archivo: src/inserter.py
# Clase: ChromaCollection.__init__()

.env â†’ load_dotenv() â†’ OpenAI Client
```

**ImplementaciÃ³n:**
- âœ… Lee `OPENAI_API_KEY` desde `.env`
- âœ… Cliente se inicializa una vez por colecciÃ³n
- âœ… Reutilizable para mÃºltiples queries

**CÃ³digo clave:**
```python
load_dotenv(find_dotenv())
self.openai_client = OpenAI(api_key=os.environ["OPENAI_API_KEY"])
```

#### 2. **ConstrucciÃ³n del Prompt** (`inserter.py`)

```python
# Archivo: src/inserter.py
# MÃ©todo: ChromaCollection.rag()

Query + Documentos â†’ Prompt â†’ GPT
```

**Estructura del prompt:**
```python
messages = [
    {
        "role": "system",
        "content": "You are an expert agent in coding..."
    },
    {
        "role": "user",
        "content": f"Question: {query}\n\nInformation:\n{information}"
    }
]
```

**Componentes:**
- **System message**: Define el rol del modelo
- **User message**: Pregunta + contexto recuperado
- **Information**: Los Top-K fragmentos unidos con `\n`

#### 3. **Llamada a la API** (`inserter.py`)

```python
response = self.openai_client.chat.completions.create(
    model="gpt-4.1-nano",
    messages=messages
)
```

**Modelo usado: GPT-4.1-nano**
- âœ… MÃ¡s rÃ¡pido y econÃ³mico ($0.10/M tokens input)
- âœ… Suficientemente capaz para RAG
- âœ… Context window: 1M tokens
- ðŸŽ¯ Ideal para este proyecto

**Alternativas disponibles:**
- `gpt-4.1-mini`: MÃ¡s capaz pero mÃ¡s caro
- `gpt-4o`: AÃºn mÃ¡s capaz (para casos complejos)
- `gpt-4`: MÃ¡xima capacidad (mÃ¡s caro)

#### 4. **ExtracciÃ³n de Respuesta**

```python
content = response.choices[0].message.content
return content
```

### Flujo Completo del RAG

```python
def rag(self, query: str, model: str = "gpt-4.1-nano") -> str:
    # 1. RETRIEVAL: Buscar fragmentos relevantes
    documents, _ = self.retrieve_k_similar_docs(query)

    # 2. AUGMENTATION: Construir contexto
    information = "\n".join(documents)
    messages = [...]

    # 3. GENERATION: Generar respuesta
    response = self.openai_client.chat.completions.create(...)
    return response.choices[0].message.content
```

---

## Pipeline de Consulta

### Estado: âœ… IMPLEMENTADO

El query pipeline maneja las preguntas del usuario.

### Flujo Paso a Paso

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Usuario hace pregunta                                â”‚
â”‚     "Â¿CÃ³mo se crea un usuario?"                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Embedding de la query                                â”‚
â”‚     Query â†’ SentenceTransformer â†’ Vector[768]            â”‚
â”‚     (AutomÃ¡tico en ChromaDB)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. BÃºsqueda de similaridad                              â”‚
â”‚     Vector query vs Todos los vectores en ChromaDB       â”‚
â”‚     Distancia coseno â†’ Top-K mÃ¡s similares               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. RecuperaciÃ³n de documentos                           â”‚
â”‚     Top-5 fragmentos mÃ¡s relevantes:                     â”‚
â”‚     - Fragment: "class Usuario: def __init__..."         â”‚
â”‚     - Fragment: "usuario1 = Usuario('Juan')"             â”‚
â”‚     - Fragment: "# Crear usuarios de prueba"             â”‚
â”‚     - etc.                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. ConstrucciÃ³n del prompt                              â”‚
â”‚     System: "Eres experto en cÃ³digo..."                  â”‚
â”‚     User: "Pregunta: ... InformaciÃ³n: [fragmentos]"      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. Llamada a GPT                                        â”‚
â”‚     OpenAI API â†’ GPT-4.1-nano procesa                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  7. Respuesta al usuario                                 â”‚
â”‚     "Para crear un usuario, usa la clase Usuario..."     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Ejemplo Concreto

**Input:**
```python
collection.rag("Â¿CÃ³mo se calcula un descuento?")
```

**Paso 1 - Retrieval:**
```python
# ChromaDB encuentra los 5 fragmentos mÃ¡s similares:
[
    "def aplicar_descuento(self, porcentaje: float) -> float: ...",
    "DESCUENTO_MAYORISTA = 0.15  # 15% de descuento",
    "descuento = self.precio * (porcentaje / 100)",
    "return self.precio - descuento",
    "if not 0 <= porcentaje <= 100: raise ValueError(...)"
]
```

**Paso 2 - Augmentation:**
```python
information = """
def aplicar_descuento(self, porcentaje: float) -> float:
    if not 0 <= porcentaje <= 100:
        raise ValueError("El porcentaje debe estar entre 0 y 100")
    descuento = self.precio * (porcentaje / 100)
    return self.precio - descuento

DESCUENTO_MAYORISTA = 0.15
...
"""
```

**Paso 3 - Generation (GPT):**
```
"El descuento se calcula con el mÃ©todo aplicar_descuento() de la clase
Producto. Este mÃ©todo toma un porcentaje (0-100) y calcula el descuento
multiplicando el precio por el porcentaje dividido 100. Luego resta el
descuento del precio original y retorna el resultado. El mÃ©todo valida
que el porcentaje estÃ© entre 0 y 100, lanzando ValueError si no lo estÃ¡."
```

---

## Estado de ImplementaciÃ³n

### âœ… Componentes Completados

| Componente | Estado | Archivo | DescripciÃ³n |
|------------|--------|---------|-------------|
| **DetecciÃ³n de lenguaje** | âœ… | `language_detector.py` | 50+ extensiones soportadas |
| **ExtracciÃ³n de ZIP** | âœ… | `text_splitter.py` | Con tempfile y limpieza automÃ¡tica |
| **Parseo de cÃ³digo** | âœ… | `text_splitter.py` | LanguageParser consciente de sintaxis |
| **Filtrado de archivos** | âœ… | `text_splitter.py` | Usa is_supported() |
| **Metadata enriquecida** | âœ… | `text_splitter.py` | source_file + language |
| **InicializaciÃ³n ChromaDB** | âœ… | `inserter.py` | Colecciones idempotentes |
| **InserciÃ³n documentos** | âœ… | `inserter.py` | Con UUID y embeddings automÃ¡ticos |
| **BÃºsqueda similaridad** | âœ… | `inserter.py` | Top-K configurable |
| **IntegraciÃ³n OpenAI** | âœ… | `inserter.py` | GPT-4.1-nano |
| **Pipeline RAG completo** | âœ… | `inserter.py` | Retrieval + Augmentation + Generation |
| **Manejo de errores** | âœ… | `text_splitter.py` | Try-catch por archivo |
| **Output informativo** | âœ… | `text_splitter.py` | SÃ­mbolos y contadores |
| **DocumentaciÃ³n** | âœ… | Todos | Docstrings sucintos |
| **Dataset de prueba** | âœ… | `test_data/` | 5 archivos + ZIP |
| **ConfiguraciÃ³n .env** | âœ… | `.env` | Template creado |
| **.gitignore** | âœ… | `.gitignore` | Actualizado para RAG |

### âŒ Componentes NO Implementados

| Componente | Estado | RazÃ³n |
|------------|--------|-------|
| **Pinecone** | âŒ | No necesario - ChromaDB es suficiente |
| **RecursiveCharacterTextSplitter** | âŒ | LanguageParser es mejor para cÃ³digo |
| **MÃ©tricas de evaluaciÃ³n** | âŒ | Pendiente (Fase avanzada) |
| **Cache de embeddings** | âŒ | OptimizaciÃ³n futura |
| **Batch queries** | âŒ | TODO en retrieve_k_similar_docs |
| **Interface web** | âŒ | Fuera del alcance del TP |

### ðŸ”„ En Progreso

| Componente | Estado | Siguiente paso |
|------------|--------|----------------|
| **Testing end-to-end** | ðŸ”„ | Ejecutar con test_codebase.zip |
| **ValidaciÃ³n de API key** | ðŸ”„ | Agregar clave real de OpenAI |

---

## CÃ³mo Ejecutar el Sistema

### Prerequisitos

1. **Activar venv:**
   ```bash
   source venv/bin/activate
   ```

2. **Verificar dependencias:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Configurar API key:**
   Edita `.env` y agrega tu clave de OpenAI:
   ```
   OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxx
   ```

### EjecuciÃ³n Completa

#### 1. Indexar el codebase de prueba

```bash
python src/text_splitter.py test_collection test_codebase.zip
```

**QuÃ© hace:**
- Extrae archivos del ZIP
- Detecta lenguajes y filtra soportados
- Parsea cada archivo
- Genera embeddings
- Inserta en ChromaDB
- Hace una query de prueba

**Output esperado:**
```
============================================================
Indexando codebase: test_codebase.zip
ColecciÃ³n: test_collection
============================================================

Cargando archivos desde ZIP...
âœ“ Parseando: config.py (python)
  â†’ 3 fragmentos extraÃ­dos
âœ“ Parseando: main.py (python)
  â†’ 5 fragmentos extraÃ­dos
âœ“ Parseando: models.py (python)
  â†’ 8 fragmentos extraÃ­dos
âœ“ Parseando: utils.py (python)
  â†’ 12 fragmentos extraÃ­dos
âœ“ Parseando: README.md (markdown)
  â†’ 2 fragmentos extraÃ­dos

============================================================
Total de fragmentos a insertar: 30
============================================================

Insertando en ChromaDB...
âœ“ Documentos insertados exitosamente

Query de prueba: 'Â¿QuÃ© funcionalidades tiene este cÃ³digo?'
============================================================

Respuesta:
Este cÃ³digo implementa un sistema de gestiÃ³n con las siguientes
funcionalidades:
- GestiÃ³n de usuarios con la clase Usuario
- CatÃ¡logo de productos con la clase Producto
- Funciones matemÃ¡ticas bÃ¡sicas (sumar, restar, multiplicar, dividir)
- Formateo de precios y cÃ¡lculo de totales
- ConfiguraciÃ³n centralizada con constantes para la aplicaciÃ³n
...
```

#### 2. Uso programÃ¡tico

```python
from src.inserter import ChromaCollection

# Conectar a la colecciÃ³n existente
collection = ChromaCollection('test_collection')

# Hacer queries
respuesta = collection.rag("Â¿CÃ³mo se crea un usuario?")
print(respuesta)

respuesta = collection.rag("Â¿QuÃ© hace la funciÃ³n aplicar_descuento?")
print(respuesta)

respuesta = collection.rag("Â¿CuÃ¡l es el valor del IVA?")
print(respuesta)
```

#### 3. Verificar fragmentos recuperados

```python
from src.inserter import ChromaCollection

collection = ChromaCollection('test_collection')

# Ver quÃ© fragmentos recupera para una query
docs, results = collection.retrieve_k_similar_docs(
    "Â¿CÃ³mo se calcula un descuento?",
    k=3
)

print("Fragmentos recuperados:")
for i, doc in enumerate(docs, 1):
    print(f"\n--- Fragmento {i} ---")
    print(doc)
```

### Troubleshooting

**Error: "No module named 'chromadb'"**
```bash
pip install chromadb
```

**Error: "OPENAI_API_KEY not found"**
- Verifica que `.env` existe en la raÃ­z
- Verifica que la lÃ­nea es exactamente: `OPENAI_API_KEY=tu_clave`
- Reinicia el script

**Error al parsear archivos**
- Normal para algunos archivos binarios
- El sistema continÃºa con los siguientes archivos
- Solo archivos soportados se procesan

**Sin fragmentos generados**
- Verifica que el ZIP contiene archivos soportados
- Aumenta `parser_threshold` si los archivos son muy pequeÃ±os

---

## Resumen Ejecutivo

### Pipeline Implementado

```
âœ… ZIP â†’ ExtracciÃ³n â†’ DetecciÃ³n â†’ Parseo â†’ ChromaDB â†’ OpenAI â†’ Respuesta
```

### Archivos Clave

1. **`src/utils/language_detector.py`**: DetecciÃ³n de lenguajes (50+ extensiones)
2. **`src/text_splitter.py`**: Indexing pipeline completo
3. **`src/inserter.py`**: ChromaDB + OpenAI + RAG
4. **`test_data/`**: Dataset de prueba funcional
5. **`.env`**: ConfiguraciÃ³n de API keys

### PrÃ³ximos Pasos

1. âœ… Agregar tu OpenAI API key real a `.env`
2. âœ… Ejecutar el sistema con `test_codebase.zip`
3. â­ï¸ Probar diferentes queries
4. â­ï¸ Evaluar calidad de respuestas
5. â­ï¸ Ajustar parÃ¡metros si es necesario (k, threshold, modelo)

### Para el TP

Tienes implementado:
- âœ… Data Loading (ZIP extraction)
- âœ… Text Splitting (LanguageParser)
- âœ… Base de Datos Vectorial (ChromaDB)
- âœ… Retrieval (bÃºsqueda semÃ¡ntica)
- âœ… TÃ©cnicas de Preprocesamiento (detecciÃ³n lenguaje, filtrado)
- âœ… Dataset (test_data con 5 archivos)

**El sistema estÃ¡ completo y funcional para el Trabajo PrÃ¡ctico.**

---

## Contacto y Referencias

- **Langchain Docs**: https://python.langchain.com/docs/
- **ChromaDB Docs**: https://docs.trychroma.com/
- **OpenAI API Docs**: https://platform.openai.com/docs/
- **SentenceTransformers**: https://www.sbert.net/

---

*Ãšltima actualizaciÃ³n: 2025-10-13*
