# Codebase RAG - Asistente Inteligente de C√≥digo

Un sistema de Retrieval-Augmented Generation (RAG) que permite consultar y comprender bases de c√≥digo usando lenguaje natural. Indexa archivos de c√≥digo en una base de datos vectorial y habilita b√∫squeda sem√°ntica con respuestas impulsadas por IA.

## Caracter√≠sticas Principales

- **Soporte multi-lenguaje**: Maneja m√°s de 30 lenguajes de programaci√≥n incluyendo Python, JavaScript, TypeScript, Java, C/C++, Go, Rust y m√°s
- **Parseo inteligente de c√≥digo**: Utiliza parsers espec√≠ficos por lenguaje (tree-sitter) para extraer fragmentos significativos
- **Recuperaci√≥n basada en vectores**: B√∫squeda por similaridad sem√°ntica usando sentence transformers
- **Respuestas impulsadas por IA**: Integraci√≥n con OpenAI GPT y Google Gemini
- **Soporte ZIP y GitHub**: Procesa codebases desde archivos zip o repositorios GitHub
- **Almacenamiento persistente**: Usa ChromaDB para recuperaci√≥n eficiente
- **Modo Chat Interactivo**: Conversaciones multi-turno con contexto mantenido

## Arquitectura

### Pipeline RAG

1. **Carga de Datos**: Archivos fuente desde ZIP o GitHub
2. **Preprocesamiento**:
   - Detecci√≥n autom√°tica del lenguaje
   - Filtrado de archivos soportados
   - Parseo espec√≠fico por lenguaje usando tree-sitter
3. **Text Splitting**: Fragmentaci√≥n inteligente respetando estructura del lenguaje
4. **Generaci√≥n de Embeddings**: Conversi√≥n a vectores usando SentenceTransformers (BERT)
5. **Almacenamiento**: Embeddings y metadata en ChromaDB
6. **Retrieval**: B√∫squeda de los K fragmentos m√°s similares sem√°nticamente
7. **Generaci√≥n**: GPT/Gemini genera respuesta usando fragmentos relevantes como contexto

### Componentes Principales

1. **Detecci√≥n de Lenguaje** (`src/utils/language_detector.py`): Identifica tipos de archivo y filtra lenguajes soportados
2. **Fragmentaci√≥n y Parseo** (`src/text_splitter.py`): Extrae y fragmenta c√≥digo usando parsers conscientes del lenguaje
3. **Almacenamiento Vectorial y RAG** (`src/inserter.py`): Gestiona ChromaDB, b√∫squeda por similaridad y generaci√≥n de respuestas

## Instalaci√≥n

### Prerequisitos

- Python 3.11 o superior
- OpenAI API key o Gemini API key

### Configuraci√≥n

```bash
# 1. Clonar repositorio
git clone <repository-url>
cd codebase-rag

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Configurar API key
echo "OPENAI_API_KEY=tu_api_key_aqui" > .env
# O alternativamente:
echo "GEMINI_API_KEY=tu_api_key_aqui" > .env
```

## Gu√≠a de Uso

### üí¨ Modo Chat Interactivo (Recomendado)

Modo conversacional que mantiene contexto entre preguntas:

```bash
# Desde archivo ZIP
python main.py -z <ruta_al_zip> --config configs/chat_openai.json

# Desde GitHub
python main.py -g <url_github> --config configs/chat_openai.json
```

**Comandos disponibles:**
- `/help`: Mostrar ayuda
- `/clear`: Reiniciar conversaci√≥n
- `/exit`: Salir del chat

**Configuraciones para chat:**

1. **`chat_openai.json`** (Recomendada): `gpt-4o-mini`, reranking habilitado, balance calidad/costo
2. **`chat_openai_fast.json`**: `gpt-3.5-turbo`, sin reranking, m√°s econ√≥mica
3. **`chat_openai_premium.json`**: `gpt-4o`, reranking agresivo, m√°xima calidad

**Nota:** Actualmente solo modelos de OpenAI soportan historial conversacional.

### üìù Modo Single-Shot

Una pregunta, una respuesta:

```bash
# Desde archivo ZIP
python main.py -z <ruta_al_zip> -p "pregunta sobre el c√≥digo"

# Desde GitHub
python main.py -g <url_github> -p "pregunta sobre el c√≥digo"

# Con opciones adicionales
python main.py -z proyecto.zip -p "¬øC√≥mo funciona la autenticaci√≥n?" \
  -c mi_coleccion --config configs/optimal.json -v
```

**Opciones CLI:**
- `-c, --collection-name`: Nombre de la colecci√≥n (default: "codeRAG")
- `--config`: Ruta al archivo de configuraci√≥n JSON
- `-v, --verbose`: Logs detallados (fragmentos recuperados, m√©tricas, tokens)

### Sistema de Configuraci√≥n JSON

El proyecto incluye 4 configuraciones predefinidas en `configs/`:

1. **`default.json`**: Balance calidad/costo (`gpt-4.1-nano`, k=5, temp=0.1)
2. **`optimal.json`**: M√°xima calidad (`gpt-4o`, k=8, embeddings mpnet)
3. **`fast.json`**: Respuestas r√°pidas (`gpt-3.5-turbo`, k=3, max_tokens=500)
4. **`detailed.json`**: An√°lisis profundo (`gpt-4.1-nano`, k=7, max_tokens=1500)

**Estructura de configuraci√≥n:**

```json
{
  "name": "mi_config",
  "prompt": {
    "template": "optimal",
    "max_context_length": 8000
  },
  "model": {
    "name": "gpt-4.1-nano",
    "temperature": 0.1,
    "max_tokens": null
  },
  "retrieval": {
    "k_documents": 5,
    "similarity_threshold": null
  },
  "embeddings": {
    "model_name": "sentence-transformers/all-MiniLM-L6-v2",
    "device": "cpu",
    "distance_function": "l2"
  }
}
```

**Par√°metros clave:**

**Prompt:**
- `template`: Plantilla (`default`, `optimal`, `detailed`, `concise`, `spanish`, `beginner_friendly`)
- `max_context_length`: L√≠mite de caracteres del contexto

**Model:**
- `name`: Modelo (`gpt-4o`, `gpt-4.1-nano`, `gpt-3.5-turbo`)
- `temperature`: Aleatoriedad (0.0-2.0, menor = m√°s determin√≠stico)
- `max_tokens`: L√≠mite de tokens en respuesta

**Retrieval:**
- `k_documents`: N√∫mero de fragmentos a recuperar
- `similarity_threshold`: Filtro de similitud m√≠nima

**Embeddings:**
- `model_name`: `all-MiniLM-L6-v2` (r√°pido) o `all-mpnet-base-v2` (mejor calidad)
- `distance_function`: `l2`, `cosine`, o `ip`

**Crear configuraci√≥n personalizada:**

```bash
cp configs/default.json configs/mi_config.json
# Editar mi_config.json seg√∫n necesidades
python main.py -z code.zip -p "pregunta" --config configs/mi_config.json
```

### Uso Program√°tico

```python
from src.config_loader import RAGConfig
from src.inserter import ChromaCollection
from src.text_splitter import load_from_zipfile

# Cargar y procesar codebase
docs = load_from_zipfile('codebase.zip')

# Inicializar colecci√≥n con configuraci√≥n
config = RAGConfig.from_json("configs/optimal.json")
collection = ChromaCollection('mi_proyecto', config=config)
collection.insert_docs(docs)

# Consultar codebase
respuesta = collection.rag("¬øC√≥mo funciona la autenticaci√≥n?")
print(respuesta)

# Recuperar documentos similares
docs_similares, _ = collection.retrieve_k_similar_docs(["funci√≥n de login"], k=5)
```

### Lenguajes Soportados

**Programaci√≥n:** Python, JavaScript/TypeScript, Java, C/C++, Go, Rust, Ruby, PHP, C#, Swift, Kotlin, Scala, Haskell, Lua, LaTeX

**Documentaci√≥n:** Markdown, JSON, YAML, TOML, XML, TXT, RST, INI, CFG

**Web:** HTML, CSS/SCSS/SASS/LESS

**Otros:** Shell scripts, SQL, R

Ver lista completa de extensiones en `src/utils/language_detector.py`.

## Evaluaci√≥n con RAGAS

El sistema incluye evaluaci√≥n basada en [RAGAS](https://docs.ragas.io/) para medir calidad del RAG.

### M√©tricas Disponibles

- **Faithfulness**: Respuestas basadas en contexto recuperado (sin alucinaciones)
- **Answer Relevancy**: Relevancia de la respuesta para la pregunta
- **Context Precision**: Precisi√≥n del contexto recuperado (requiere referencias)
- **Context Recall**: Completitud del contexto (requiere referencias)

### Evaluaci√≥n R√°pida

```bash
# 1. Preparar dataset de prueba (ver data/evaluation/test_queries.json)
# 2. Ejecutar evaluaci√≥n
python evaluate.py \
  --collection-name codeRAG \
  --test-dataset data/evaluation/test_queries.json \
  --metrics faithfulness,answer_relevancy

# 3. Ver resultados en results/evaluation_results.csv
```

### Opciones Avanzadas

```bash
# Auto-generar queries de prueba
python evaluate.py --collection-name codeRAG --auto-generate 20 \
  --save-dataset data/evaluation/my_queries.json

# Generar referencias autom√°ticamente
python evaluate.py --test-dataset queries.json --generate-references \
  --save-dataset queries_with_refs.json

# Curaci√≥n interactiva
python evaluate.py --test-dataset queries.json --interactive-curation
```

### Formato del Dataset

```json
{
  "samples": [
    {
      "question": "¬øC√≥mo funciona la autenticaci√≥n?",
      "reference": "La autenticaci√≥n se maneja mediante...",
      "metadata": {"category": "security", "difficulty": "medium"}
    }
  ]
}
```

### Interpretando Resultados

**Rangos de puntuaci√≥n (0.0 - 1.0):**
- **0.8 - 1.0**: Excelente
- **0.6 - 0.8**: Bueno
- **0.4 - 0.6**: Regular - Necesita optimizaci√≥n
- **< 0.4**: Pobre - Requiere cambios significativos

Ver `configs/evaluation.json` para configurar modelo evaluador, m√©tricas y batch size.

## Datasets de Prueba

El directorio `dataset/` contiene proyectos de prueba:

1. **SMTP-Protos** (~200KB): Protocolo de red en C - pruebas r√°pidas
2. **jam-py** (~15MB): Framework web JavaScript/Python - parseo multi-lenguaje
3. **NumPy** (~10MB): Librer√≠a cient√≠fica Python/C - c√≥digo cient√≠fico complejo

```bash
python main.py -z dataset/numpy-main.zip -p "¬øQu√© hace la funci√≥n array?"
```

## Estructura del Proyecto

```
codebase-rag/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ inserter.py              # ChromaDB e implementaci√≥n RAG
‚îÇ   ‚îú‚îÄ‚îÄ text_splitter.py         # Parseo de archivos
‚îÇ   ‚îú‚îÄ‚îÄ config_loader.py         # Cargador de configs
‚îÇ   ‚îú‚îÄ‚îÄ prompt_loader.py         # Plantillas de prompts
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îî‚îÄ‚îÄ language_detector.py # Detecci√≥n de lenguaje
‚îú‚îÄ‚îÄ configs/                      # Configuraciones JSON
‚îú‚îÄ‚îÄ prompts/                      # Plantillas de prompts
‚îú‚îÄ‚îÄ dataset/                      # Datasets de prueba
‚îú‚îÄ‚îÄ data/evaluation/              # Queries de evaluaci√≥n
‚îú‚îÄ‚îÄ results/                      # Resultados de evaluaci√≥n
‚îú‚îÄ‚îÄ main.py                       # CLI principal
‚îú‚îÄ‚îÄ evaluate.py                   # CLI de evaluaci√≥n
‚îî‚îÄ‚îÄ requirements.txt
```

## Testing

```bash
# Tests de detecci√≥n de lenguaje
python tests/test_language_detector.py

# Tests de evaluador RAGAS
python tests/test_ragas_evaluator.py
```

## Dependencias Principales

- `chromadb`: Base de datos vectorial
- `openai`: Integraci√≥n con GPT
- `langchain`: Procesamiento de documentos
- `sentence-transformers`: Generaci√≥n de embeddings
- `tree-sitter`: Parseo consciente del lenguaje
- `ragas`: Framework de evaluaci√≥n RAG

Ver [requirements.txt](requirements.txt) para la lista completa.

## Limitaciones Actuales

- Requiere API key de OpenAI o Gemini (costos por uso)
- Archivos binarios e im√°genes no soportados
- Rendimiento depende del tama√±o de la codebase
- Calidad depende de la relevancia de fragmentos recuperados

## Mejoras Futuras

- Embeddings especializados en c√≥digo
- Soporte para lenguajes de programaci√≥n adicionales
- Metadata filtering avanzado
- Agentic RAG
- Escalabilidad a repos > 100K docs

## Licencia

Este proyecto se proporciona tal cual para fines educativos y de desarrollo.
